{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2ed04cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e4074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46da6952",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = dataset.get(\"data\"), dataset.get(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c0c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18915b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c641012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        super(CustomDataset).__init__()\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        target = self.target[idx]\n",
    "        return {\n",
    "            \"data\": torch.tensor(data, dtype=torch.float32).to(device),\n",
    "            \"target\": torch.tensor(target, dtype = torch.float32).to(device)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edfae4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "test_dataset = CustomDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ff6d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size = 4\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae5e4ee",
   "metadata": {},
   "source": [
    "## Model Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43abb30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lambda x, w, b: (torch.matmul(x, w) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6590fd",
   "metadata": {},
   "source": [
    "Calculating Linear Regression \n",
    "\n",
    "- Compute the Output \n",
    "$$Y_{hat} = W^TX + b$$\n",
    "\n",
    "- Calculate Loss MSE\n",
    "$$MSE = \\frac{1}{n}\\Sigma_0^n(y - y_{hat}) ^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c79b6751",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn(8, 1, requires_grad=True, device=device)\n",
    "b = torch.randn(1, requires_grad=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d3162bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.955566644668579"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3732e674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss: torch.mean(torch.from_numpy(np.array(epoch_loss)))=tensor(0.9937, dtype=torch.float64)\n",
      "Epoch Loss: torch.mean(torch.from_numpy(np.array(epoch_loss)))=tensor(0.7549, dtype=torch.float64)\n",
      "Epoch Loss: torch.mean(torch.from_numpy(np.array(epoch_loss)))=tensor(2.2464, dtype=torch.float64)\n",
      "Epoch Loss: torch.mean(torch.from_numpy(np.array(epoch_loss)))=tensor(10.7577, dtype=torch.float64)\n",
      "Epoch Loss: torch.mean(torch.from_numpy(np.array(epoch_loss)))=tensor(90.2122, dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-221c83511c70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gpu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\gpu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-72aa1db73efd>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         return {\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[1;34m\"data\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[1;34m\"target\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         }\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-3\n",
    "best_loss, best_W, best_b = None, None, None\n",
    "for epoch in range(10):\n",
    "    epoch_loss = []\n",
    "    for data in train_loader:\n",
    "        x, y = data[\"data\"], data[\"target\"]\n",
    "        output = model(x, W, b)\n",
    "        \n",
    "        loss = torch.mean((y.view(-1) - output.view(-1)) ** 2)\n",
    "        loss.backward() # TO calculate the gradients\n",
    "        epoch_loss.append(loss.item())\n",
    "        \n",
    "#         print(f\"{epoch=}: {loss=}\")\n",
    "        with torch.no_grad(): # Its a context manager, it will disable all the previous requirements like required_grads\n",
    "            W = W - (learning_rate * W.grad)\n",
    "            b = b - (learning_rate * b.grad)\n",
    "        \n",
    "        # Refresh the context with requiring the grads\n",
    "        W.requires_grad_(True)\n",
    "        b.requires_grad_(True)\n",
    "    mean_epoch_loss = torch.mean(torch.from_numpy(np.array(epoch_loss)))\n",
    "    if best_loss == None or best_loss > mean_epoch_loss.item():\n",
    "        best_loss = mean_epoch_loss.item()\n",
    "        best_W = W\n",
    "        best_b = b\n",
    "    print(f\"Epoch Loss: {torch.mean(torch.from_numpy(np.array(epoch_loss)))=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ffcb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "063e938e",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2fa734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "\n",
    "for test_data in test_loader:\n",
    "    data, target = test_data[\"data\"], test_data[\"target\"]\n",
    "    with torch.no_grad():\n",
    "        resp = model(data, best_W, best_b)\n",
    "    outputs.append(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80218f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4510, 1.0673, 1.2813,  ..., 2.2304, 2.2944, 2.4713],\n",
       "        [0.9381, 2.0406, 2.3138,  ..., 2.1326, 2.4139, 1.9525],\n",
       "        [2.4843, 2.8793, 1.4926,  ..., 2.4963, 1.4456, 2.4560],\n",
       "        [2.1921, 2.8440, 2.3659,  ..., 1.2171, 2.5133, 2.6391]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba2a82d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor = torch.cat(outputs, dim=-1).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c07859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = lambda out1, out2: torch.mean((out1 - out2) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafdc2de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "485fff47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4510, 1.0673, 1.2813,  ..., 1.2171, 2.5133, 2.6391], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5041c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_tensor = torch.tensor(y_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06c4f194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.372723926109867"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_test_tensor, output_tensor).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d190704e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab8a1ee3",
   "metadata": {},
   "source": [
    "## Training and Validation Loop\n",
    "\n",
    "This section is dedicated to model training and validation in a structured manner. \n",
    "\n",
    "1. We are initializing the training loop for the model \n",
    "2. For every iteration, we are going to use multiple callbacks for easy training\n",
    "3. After completion of model training, we are going to use the validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "205fae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_calc(model, data, target):\n",
    "    model_output = model(data, W, b)\n",
    "    y_output = target.view(-1) # Original Output\n",
    "    model_output = model_output.view(-1) # Reshaping predicted output\n",
    "    return torch.mean((y_output - model_output) ** 2)\n",
    "\n",
    "def train_one_step(model, data, optimizer):\n",
    "    \"\"\"\n",
    "    For each step, we have to follow\n",
    "    - Initialize the optimizer gredients to zero\n",
    "    - Perform forward Pass\n",
    "    - Calculate batch error/loss\n",
    "    - Take loss backward pass\n",
    "    - Update weights using optimizer steps\n",
    "    - Return loss \n",
    "    \"\"\"\n",
    "    loss = loss_calc(model, **data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad() # This will re-initialize every gredients to zero\n",
    "    return loss.item()\n",
    "\n",
    "def train_one_epoch(model, data_loader, optimizer):\n",
    "    \"\"\"\n",
    "    For each epoch, \n",
    "    - Iterate over the complete training data.\n",
    "    - Calculate the step loss \n",
    "    - Compute the epoch average loss\n",
    "    - Print the average loss and return to the user\n",
    "    \"\"\"\n",
    "#     model.train() # Setting model state to train only works with module API\n",
    "    total_loss = 0\n",
    "\n",
    "    for idx, data in enumerate(data_loader):\n",
    "        step_loss = train_one_step(model, data, optimizer)\n",
    "        total_loss += step_loss\n",
    "#         scheduler.step()\n",
    "    return total_loss / (idx + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "58670c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Loop\n",
    "\n",
    "def eval_one_epoch(model, data_loader):\n",
    "#     model.eval() # Disabling the gredient calculation only works with Module API\n",
    "    total_loss = 0\n",
    "    for idx, data in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            loss = loss_calc(model, **data)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / (idx + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7fae17d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bb5bf4840749d2945cdecbfeab3901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss @ epoch=0: 8.3791763422823\n",
      "Validation Loss @epoch=0: 2.131917714143114\n",
      "Training Loss @ epoch=1: 0.9859590346538263\n",
      "Validation Loss @epoch=1: 0.7275682775892115\n",
      "Training Loss @ epoch=2: 0.6317201307458671\n",
      "Validation Loss @epoch=2: 0.6230825289935884\n",
      "Training Loss @ epoch=3: 0.5571011994899271\n",
      "Validation Loss @epoch=3: 0.6380147487971961\n",
      "Training Loss @ epoch=4: 0.5363461275971017\n",
      "Validation Loss @epoch=4: 0.666968245555145\n",
      "Training Loss @ epoch=5: 0.5317289391160283\n",
      "Validation Loss @epoch=5: 0.6966582339734395\n",
      "Training Loss @ epoch=6: 0.5311922209253652\n",
      "Validation Loss @epoch=6: 0.7230658169561462\n",
      "Training Loss @ epoch=7: 0.5315681575440356\n",
      "Validation Loss @epoch=7: 0.7458852321566479\n",
      "Training Loss @ epoch=8: 0.5320888342636559\n",
      "Validation Loss @epoch=8: 0.7655730084985379\n",
      "Training Loss @ epoch=9: 0.5325827124998309\n",
      "Validation Loss @epoch=9: 0.7826391488292016\n"
     ]
    }
   ],
   "source": [
    "W = torch.randn((8, 1), dtype=torch.float32, device=device, requires_grad=True)\n",
    "b = torch.randn(1, dtype=torch.float32, device=device, requires_grad=True)\n",
    "def train_model(epochs):\n",
    "    optimizer = torch.optim.Adam([W, b])\n",
    "#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer)\n",
    "        tqdm.write(f\"Training Loss @ {epoch=}: {train_loss}\")\n",
    "        valid_loss = eval_one_epoch(model, test_loader)\n",
    "        tqdm.write(f\"Validation Loss @{epoch=}: {valid_loss}\")\n",
    "\n",
    "train_model(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9284b770",
   "metadata": {},
   "source": [
    "# Linear Regression using Pytorch Module API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7494dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp_dim, out_dim):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(inp_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, out_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x = self.fc1(data)\n",
    "        x = self.fc2(x)\n",
    "        return self.activation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "66201a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RegressionModel(8, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "540b83e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_calc(model, data, target):\n",
    "    model_output = model(data)\n",
    "    y_output = target.view(-1) # Original Output\n",
    "    model_output = model_output.view(-1) # Reshaping predicted output\n",
    "    return torch.mean((y_output - model_output) ** 2)\n",
    "\n",
    "def train_one_step(model, data, optimizer):\n",
    "    \"\"\"\n",
    "    For each step, we have to follow\n",
    "    - Initialize the optimizer gredients to zero\n",
    "    - Perform forward Pass\n",
    "    - Calculate batch error/loss\n",
    "    - Take loss backward pass\n",
    "    - Update weights using optimizer steps\n",
    "    - Return loss \n",
    "    \"\"\"\n",
    "    loss = loss_calc(model, **data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad() # This will re-initialize every gredients to zero\n",
    "    return loss.item()\n",
    "\n",
    "def train_one_epoch(model, data_loader, optimizer):\n",
    "    \"\"\"\n",
    "    For each epoch, \n",
    "    - Iterate over the complete training data.\n",
    "    - Calculate the step loss \n",
    "    - Compute the epoch average loss\n",
    "    - Print the average loss and return to the user\n",
    "    \"\"\"\n",
    "    model.train() # Setting model state to train only works with module API\n",
    "    total_loss = 0\n",
    "\n",
    "    for idx, data in enumerate(data_loader):\n",
    "        step_loss = train_one_step(model, data, optimizer)\n",
    "        total_loss += step_loss\n",
    "#         scheduler.step()\n",
    "    return total_loss / (idx + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e86dda24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Loop\n",
    "\n",
    "def eval_one_epoch(model, data_loader):\n",
    "    model.eval() # Disabling the gredient calculation only works with Module API\n",
    "    total_loss = 0\n",
    "    for idx, data in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            loss = loss_calc(model, **data)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / (idx + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b6ea8d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55dbaca9bb5487a8343553f756a0bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss @ epoch=0: 0.6217589719412089\n",
      "Validation Loss @epoch=0: 0.5757515416530236\n",
      "Training Loss @ epoch=1: 0.5712738023626293\n",
      "Validation Loss @epoch=1: 0.6074643328491699\n",
      "Training Loss @ epoch=2: 0.5238559984895554\n",
      "Validation Loss @epoch=2: 0.5782567869978794\n",
      "Training Loss @ epoch=3: 0.5236196047128964\n",
      "Validation Loss @epoch=3: 0.5347887690660955\n",
      "Training Loss @ epoch=4: 0.5218709047054403\n",
      "Validation Loss @epoch=4: 0.524489064716243\n",
      "Training Loss @ epoch=5: 0.52273030110259\n",
      "Validation Loss @epoch=5: 0.5151529439531859\n",
      "Training Loss @ epoch=6: 0.52283830619002\n",
      "Validation Loss @epoch=6: 0.5092880690074165\n",
      "Training Loss @ epoch=7: 0.5229796854927576\n",
      "Validation Loss @epoch=7: 0.5029654128331684\n",
      "Training Loss @ epoch=8: 0.5873228463704351\n",
      "Validation Loss @epoch=8: 0.5518924326772617\n",
      "Training Loss @ epoch=9: 0.5120735686545823\n",
      "Validation Loss @epoch=9: 0.5527669904097489\n"
     ]
    }
   ],
   "source": [
    "def train_model(epochs):\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer)\n",
    "        tqdm.write(f\"Training Loss @ {epoch=}: {train_loss}\")\n",
    "        valid_loss = eval_one_epoch(model, test_loader)\n",
    "        tqdm.write(f\"Validation Loss @{epoch=}: {valid_loss}\")\n",
    "\n",
    "train_model(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2fd992a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of RegressionModel(\n",
       "  (fc1): Linear(in_features=8, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (activation): ReLU()\n",
       ")>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model, \"regression_model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27852b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
